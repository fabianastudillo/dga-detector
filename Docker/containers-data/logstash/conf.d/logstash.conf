input {
  gelf {
# This information is send using graylog from CEDIA
    port => 10000
    use_tcp => true
#    type => "gelf"
  }
#  file {
##    path => ["/var/log/suricata/eve.json"]
##    path => ["/var/log/suricata/eve-%{+YYYY-MM-dd}.json"]
#    path => ["/var/log/suricata/eve-*.json"]
##    sincedb_path => ["/var/lib/logstash/sincedb"]
#    sincedb_path => ["/usr/share/logstash/since.db"]
#    codec => json
#    type => "suricata"
#  }
}

filter {
#    date {
#      match => [ "timestamp", "ISO8601" ]
#    }
#    ruby {
#      code => "if event['event_type'] == 'fileinfo'; event['fileinfo']['type']=event['fileinfo']['magic'].to_s.split(',')[0]; end;" 
#    }
  
#  if [type] == "gelf" {
    mutate {
      add_field => { "[dns][type]" => "query" }
      rename => {"ip" => "src_ip"}
      rename => {"gl2_remote_ip" => "dest_ip"}
      rename => {"gl2_remote_port" => "dest_port"}
      rename => {"name" => "[dns][rrname]"}
      rename => {"type"=> "[dns][rrtype]"}
      rename => {"rescode" => "[dns][rcode]"}
#      add_field => { "event_type" => "dns"}
      add_field => { "[dns][ip]" => "%{[dns][rrname]}" }
    }

    if [dns][rcode] {
      mutate {
        replace => [ "[dns][type]", "answer" ]
      }
    } else {
      mutate {
        replace => [ "[dns][rcode]", "QUERY" ]
      }
    }

    if [src_ip] =~ "^10.0.*" or [src_ip] =~ "^127.0.*" or [src_ip] == "0.0.0.0" { 
      mutate {
        add_tag => ["internal"]
      }
    }

    tld {
      source => "[dns][rrname]"
      target => "dn"
    }

    mutate{
      remove_field => ["[geoip][continent_code]","[geoip][country_code2]","[geoip][country_code3]","[geoip][latitude]","[geoip][location]","[geoip][longitude]","[geoip][region_code]","[geoip][region_name]","[geoip][timezone]","[geoip][dma_code]","[geoip][postal_code]"]
      remove_field => ["type","tags","path","host","[dns][qr]","[dns][flags]","[dns][tc]","[dns][rd]","[dns][ra]"]  
      remove_field => ["[dns][aa]","[dns][answers]","[dns][version]","[dns][authorities]"]
      remove_field => ["[dns][tx_id]"]
      remove_field => ["[dn][domain]","[dn][subdomain]","[dn][trd]"]
      remove_field => ["gl2_message_id","forwarder","facility_num","cached","remove_ip_city_name","facility_num","gl2_source_node","gl2_source_input","ip_country_code","host","facility"]
      remove_field => ["message","version","id","loglevel","ip_geolocation"]
    }

  # https://www.elastic.co/blog/using-logstash-to-split-data-and-send-it-to-multiple-outputs

    clone {
      clones => ['lasticsearch', 'dgam']
    }
    if [type] == 'dgam' {
  #      json {
  #        source => "message"
  #        target => "dgam"
  #      }
      mutate {
        add_field => { 
          "rescode" => "%{[dns][rcode]}"
          "name" => "%{[dn][sld]}"
        } 
      }
      prune {
        whitelist_names => ["src_ip","rescode","^name$"]
      }
      mutate {
        add_field => { "[@metadata][type]" => "dgam" } 
      }
    }
#  }
}

output {

#  stdout { 
#    codec =>  rubydebug {
#      metadata => true
#    }
#  }
  if [@metadata][type] == 'dgam' {
#    file {
#      path => ["/var/log/dgam.log"]
#      codec => line { format => "%{src_ip} %{name} %{rescode}"}
#    }
    tcp {
      host => "dgam"
      port => "9999"
      codec => line { format => "%{src_ip} %{name} %{rescode}"}
    }
  }
#  else 
#  {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "logstash-dns-%{+YYYY.MM.dd}"
#        index => "logstash-dns-%{+YYYY.MM.dd}"
    }
#    file {
#      path => ["/var/log/elasticsearch.log"]
#    }
#  }
}
